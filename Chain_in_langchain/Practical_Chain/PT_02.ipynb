{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9353fe",
   "metadata": {},
   "source": [
    "THat is use Runnables in chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27359ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ab9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c331ce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd22404",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms=HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4028d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatHuggingFace(llm=llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76d4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_01=PromptTemplate(\n",
    "    template=\"write a summary of the following text: {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f3161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_02=PromptTemplate(\n",
    "    template=\"Tell me a joke about {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cffdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f03f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with the text about data scientists that you would like summarized. \n",
      "\n",
      "For example, you could provide:\n",
      "\n",
      "* **A paragraph from an article:** \"Data scientists are in high demand as businesses seek insights from their data. They use statistical methods, programming languages, and machine learning algorithms to analyze data and find patterns that can be used to make more informed decisions.\"\n",
      "* **A definition from a website:** \"Data scientists are highly skilled professionals who use analytical tools and techniques to extract meaning from data, enabling businesses to make better decisions.\"\n",
      "* **A list of responsibilities:** \"Data scientists are responsible for collecting, cleaning, and analyzing data, interpreting results, and communicating findings to stakeholders. They also play a key role in developing and deploying predictive models.\" \n",
      "\n",
      "\n",
      "Once you provide the text, I can summarize it for you. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain=template_01 | model | parser\n",
    "results=chain.invoke({\"text\":\"Data Scientists\"})\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e363d227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text is  2488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Recursion, in the realms of computer science, is a powerful programming technique where a function calls itself within its own definition. Imagine a set of nested Russian dolls â€“ each doll contains a smaller version of itself. Recursion in programming operates in a similar manner, with the function \"calling itself\" to solve a problem that can be broken down into smaller, self-similar subproblems. \\n\\nHere\\'s a breakdown to clarify:\\n\\n**Core Concepts**\\n\\n* **Base Case:** Every recursive function must have a stopping condition, a base case that prevents infinite loops or redundant computations. This base case effectively concludes the recursion, giving it a clear exit point.\\n* **Recursive Case:** This is where the function calls itself, taking a chunk of the problem and simplifying it into smaller, self-similar parts.\\n* **Stack:** When a recursive function calls itself, its execution is stored on the call stack. Each call creates a new frame on the stack, holding variables and values related to that specific call. \\n\\n**Visual Analogy:**\\n\\nThink of a recursive function like a set of instructions that resembles a \"tower of instructions\".  \\n\\n* **Step 1:** You begin with a task (the \"top level instruction\")\\n* **Step 2:**  The instruction calls itself (the \"recursive call\") to break down the problem into smaller pieces. \\n* **Step 3:** Each \"smaller piece\" becomes another instruction, each further broken down until you reach the base case that would resolve the original task. \\n\\n\\n**Benefits of Recursion:**\\n\\n* **Elegance:** Recursive solutions can express complex, tree-based structures in a compact and elegant manner. \\n* **Readability:** Recursion can often make a program more readable compared to iterative solutions for some problems.\\n\\n**Limitations:**\\n\\n* **Stack Overflow:**  Recursive functions can lead to stack overflow errors if the call depth becomes excessive. This happens because too many recursive calls consume memory and can make your program crash. \\n* **Performance Considerations:** Recursion can be less efficient than iterative solutions. This is because it involves storing function calls on the call stack, which can add overhead.\\n\\n**Examples:**\\n\\n* **Factorial (Calculating factorials):**  The factorial of a number is the product of all positive integers less than or equal to that number. \\n* **Fibonacci Sequence:** This famous mathematical sequence is defined recursively (explained below). \\n* **Searching in a Tree:** Recursively traversing a tree data'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "def length_check(text:str)->str:\n",
    "    print('length of text is ',len(text))\n",
    "    return text\n",
    "\n",
    "log_length = RunnableLambda(length_check)\n",
    "# Chain with custom logic\n",
    "chain = (\n",
    "    ChatPromptTemplate.from_template(\"Define {word}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | log_length # Pipes string into function, returns string\n",
    ")\n",
    "\n",
    "chain.invoke({\"word\": \"Recursion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc416697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Define the Runnables\n",
    "# prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# parser = StrOutputParser()\n",
    "\n",
    "# # 2. Create the Chain using the Pipe operator\n",
    "# # The dict input flows into prompt, prompt output flows into model, etc.\n",
    "# chain = prompt | model | parser\n",
    "\n",
    "# # 3. Invoke\n",
    "# result = chain.invoke({\"topic\": \"Data Scientists\"})\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c63bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# def length_check(text: str) -> str:\n",
    "#     \"\"\"Custom function to inspect output\"\"\"\n",
    "#     print(f\"Length of joke: {len(text)}\")\n",
    "#     return text\n",
    "\n",
    "# # RunnableLambda explicitly wraps the function (optional, often implicit)\n",
    "# log_length = RunnableLambda(length_check)\n",
    "\n",
    "# # Chain with custom logic\n",
    "# chain = (\n",
    "#     ChatPromptTemplate.from_template(\"Define {word}\")\n",
    "#     | model\n",
    "#     | StrOutputParser()\n",
    "#     | log_length # Pipes string into function, returns string\n",
    "# )\n",
    "\n",
    "# chain.invoke({\"word\": \"Recursion\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
